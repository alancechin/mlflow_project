{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Temp\\ipykernel_12716\\1383000715.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "## biblio que salva objetos criados para serem utilizados posteriormente\n",
    "import joblib\n",
    "## biblio para manipular dados tabulares\n",
    "import pandas as pd\n",
    "### biblio para validação dos dados de entrada\n",
    "import pandera  \n",
    "from pandera import Check, Column, DataFrameSchema\n",
    "### biblio para separação de amostras de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "### método que auxilia no processo do fluxo de tratamento dos dados de treino e teste sem enviesar os dados\n",
    "from sklearn.pipeline import Pipeline\n",
    "### métodos de preprocessamento\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser, EqualWidthDiscretiser\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "## método para avaliar performance do modelo  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "## método que disponibiliza o modelo utilizado \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Utils\n",
    "Funções e variáveis reutilizáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['target', 'TaxaDeUtilizacaoDeLinhasNaoGarantidas',\n",
    "       'Idade', 'NumeroDeVezes30-59DiasAtrasoNaoPior', 'TaxaDeEndividamento',\n",
    "       'RendaMensal', 'NumeroDeLinhasDeCreditoEEmprestimosAbertos',\n",
    "       'NumeroDeVezes90DiasAtraso', 'NumeroDeEmprestimosOuLinhasImobiliarias',\n",
    "       'NumeroDeVezes60-89DiasAtrasoNaoPior', 'NumeroDeDependentes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0. Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classe que encapsula etapa de carregamento dos dados\n",
    "class DataLoad:\n",
    "    \"\"\"Class data load\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass \n",
    "    \n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Funcao vai carregar os dados\n",
    "        \n",
    "        return:\n",
    "            pandas DataFrame\"\"\"\n",
    "            \n",
    "        loaded_data = pd.read_csv('../data/raw/train.csv')\n",
    "        return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>TaxaDeUtilizacaoDeLinhasNaoGarantidas</th>\n",
       "      <th>Idade</th>\n",
       "      <th>NumeroDeVezes30-59DiasAtrasoNaoPior</th>\n",
       "      <th>TaxaDeEndividamento</th>\n",
       "      <th>RendaMensal</th>\n",
       "      <th>NumeroDeLinhasDeCreditoEEmprestimosAbertos</th>\n",
       "      <th>NumeroDeVezes90DiasAtraso</th>\n",
       "      <th>NumeroDeEmprestimosOuLinhasImobiliarias</th>\n",
       "      <th>NumeroDeVezes60-89DiasAtrasoNaoPior</th>\n",
       "      <th>NumeroDeDependentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  TaxaDeUtilizacaoDeLinhasNaoGarantidas  Idade  \\\n",
       "0       1                               0.766127     45   \n",
       "1       0                               0.957151     40   \n",
       "2       0                               0.658180     38   \n",
       "3       0                               0.233810     30   \n",
       "4       0                               0.907239     49   \n",
       "\n",
       "   NumeroDeVezes30-59DiasAtrasoNaoPior  TaxaDeEndividamento  RendaMensal  \\\n",
       "0                                    2             0.802982       9120.0   \n",
       "1                                    0             0.121876       2600.0   \n",
       "2                                    1             0.085113       3042.0   \n",
       "3                                    0             0.036050       3300.0   \n",
       "4                                    1             0.024926      63588.0   \n",
       "\n",
       "   NumeroDeLinhasDeCreditoEEmprestimosAbertos  NumeroDeVezes90DiasAtraso  \\\n",
       "0                                          13                          0   \n",
       "1                                           4                          0   \n",
       "2                                           2                          1   \n",
       "3                                           5                          0   \n",
       "4                                           7                          0   \n",
       "\n",
       "   NumeroDeEmprestimosOuLinhasImobiliarias  \\\n",
       "0                                        6   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        1   \n",
       "\n",
       "   NumeroDeVezes60-89DiasAtrasoNaoPior  NumeroDeDependentes  \n",
       "0                                    0                  2.0  \n",
       "1                                    0                  1.0  \n",
       "2                                    0                  0.0  \n",
       "3                                    0                  0.0  \n",
       "4                                    0                  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Instanciando a classe DataLoad\n",
    "dl = DataLoad()\n",
    "\n",
    "### Instanciando objeto que receberá dataframe treino\n",
    "df = dl.load_data()[columns_to_use]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0. Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    \"\"\"Classe usada para checar/validar a conformidade do dataframe de treino na entrada\"\"\"\n",
    "    def __init__(self, columns_to_use) -> None: ## initialize método recebe as colunas que devem estar contidas nos dados de treino\n",
    "        self.columns_to_use = columns_to_use\n",
    "    \n",
    "    def check_shape_data(self, dataframe: pd.DataFrame) -> bool:  ## recebe um dataframe e verifica se contém as colunas desejadas\n",
    "        try:\n",
    "            print('Validacao iniciou')\n",
    "            dataframe.columns = self.columns_to_use\n",
    "            return True \n",
    "        except Exception as e:\n",
    "            print(f'Validacao errou: {e}')\n",
    "            return False\n",
    "        \n",
    "    ## método que checa coluna por coluna relativo aos tipos de dados e Check(lambda x: x > 0), coerce=True verifica nulos para target\n",
    "        ### para outras colunas aceita colunas com nulos pois posteriormente será tratada.\n",
    "    def check_columns(self, dataframe: pd.DataFrame) -> bool: \n",
    "        schema = DataFrameSchema(\n",
    "                {\n",
    "                    \"target\": Column(int, Check.isin([0, 1]), Check(lambda x: x > 0), coerce=True),\n",
    "                    \"TaxaDeUtilizacaoDeLinhasNaoGarantidas\": Column(float, nullable=True),\n",
    "                    \"Idade\": Column(int, nullable=True),\n",
    "                    \"NumeroDeVezes30-59DiasAtrasoNaoPior\": Column(int, nullable=True),\n",
    "                    \"TaxaDeEndividamento\": Column(float, nullable=True),\n",
    "                    \"RendaMensal\": Column(float, nullable=True),\n",
    "                    \"NumeroDeLinhasDeCreditoEEmprestimosAbertos\": Column(int, nullable=True),\n",
    "                    \"NumeroDeVezes90DiasAtraso\": Column(int, nullable=True),\n",
    "                    \"NumeroDeEmprestimosOuLinhasImobiliarias\": Column(int, nullable=True),\n",
    "                    \"NumeroDeVezes60-89DiasAtrasoNaoPior\": Column(int, nullable=True),\n",
    "                    \"NumeroDeDependentes\": Column(float, nullable=True)\n",
    "                }\n",
    "            )\n",
    "        try:\n",
    "            schema.validate(dataframe)\n",
    "            print(\"Validation columns passed...\")\n",
    "            return True\n",
    "        except pandera.errors.SchemaErrors as exc:\n",
    "            print(\"Validation columns failed...\")\n",
    "            pandera.display(exc.failure_cases)\n",
    "        return False\n",
    "    \n",
    "    ## método executor da classe que irá chamar os outros métodos e orquestrar as validações\n",
    "    def run(self, dataframe: pd.DataFrame) -> bool:\n",
    "        if self.check_shape_data(dataframe) and self.check_columns(dataframe):\n",
    "            print('Validacao com sucesso.')\n",
    "            return True \n",
    "        else:\n",
    "            print('Validacao falhou.')\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacao iniciou\n",
      "Validation columns passed...\n",
      "Validacao com sucesso.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Instanciando a classe e passar os argumentos necessários\n",
    "dv = DataValidation(columns_to_use)\n",
    "\n",
    "## chamando a classe com o método principal\n",
    "dv.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Data Transformation \n",
    "Realizar algum tipo de transformação nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, dataframe: pd.DataFrame, target_name: str):\n",
    "        self.dataframe = dataframe \n",
    "        self.target_name = target_name \n",
    "        \n",
    "    def train_test_spliting(self): ### função que realiza a separação dados de treino e validação\n",
    "        X = self.dataframe.drop(self.target_name, axis=1)\n",
    "        y = self.dataframe[self.target_name]\n",
    "        \n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DataTransformation(df, 'target')\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = dt.train_test_spliting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112500, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Data preprocess\n",
    "\n",
    "Feature Engineering, data preparation (encoding, scaler) and fillna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess: ### classe que recebe um dataframe e o objeto instanciado Pipeline\n",
    "    def __init__(self, dataframe: pd.DataFrame,\n",
    "                       pipe: Pipeline):\n",
    "        self.dataframe = dataframe\n",
    "        self.pipe = pipe \n",
    "        \n",
    "    def pipeline(self): ### ira fitar os dados de treino\n",
    "        train_pipe = self.pipe\n",
    "        train_pipe.fit(self.dataframe)\n",
    "        return train_pipe \n",
    "    \n",
    "    def run(self):\n",
    "        print('Preprocessador iniciou...')\n",
    "        trained_pipeline = self.pipeline() ### traz o pipeline treinado\n",
    "        data_preprocessed = trained_pipeline.transform(self.dataframe) ### realiza transformação\n",
    "        return data_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imputer é para tratar nulos , já os outros são para padronizaçâo de variáveis\n",
    "pipe = Pipeline([('imputer', MeanMedianImputer(variables=['RendaMensal',\n",
    "                                                          'NumeroDeDependentes'])),\n",
    "                 ('discretizer', EqualFrequencyDiscretiser(variables=['TaxaDeUtilizacaoDeLinhasNaoGarantidas',\n",
    "                                                                      'TaxaDeEndividamento',\n",
    "                                                                      'RendaMensal'])),\n",
    "                 ('scaler', SklearnTransformerWrapper(StandardScaler()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chama classe\n",
    "dp = DataPreprocess(X_train, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sai com dataframe processado\n",
    "X_train_processed = dp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dados de entrada sem preprocessamento\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dados de entrada com preprocessamento\n",
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### salvar a arquitetura do preprocessador utilizado\n",
    "joblib.dump(dp.pipeline(),\n",
    "            'preprocessor.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModels:\n",
    "    def __init__(self, dados_X: pd.DataFrame,\n",
    "                       dados_y: pd.DataFrame):\n",
    "        self.dados_X = dados_X \n",
    "        self.dados_y = dados_y \n",
    "        \n",
    "    def train(self, model):\n",
    "        model.fit(self.dados_X, self.dados_y)\n",
    "        joblib.dump(model, 'modelo.joblib')\n",
    "        return model \n",
    "    \n",
    "    def predict(self, dados_para_prever: pd.DataFrame):\n",
    "        model_fitted = self._load_model()\n",
    "        dados_pred = model_fitted.predict_proba(dados_para_prever)\n",
    "        return dados_pred\n",
    "    \n",
    "    def _load_model(self):\n",
    "        model = joblib.load('modelo.joblib')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TrainModels(dados_X=X_train_processed,\n",
    "                 dados_y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.train(model=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = tm.predict(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = dp.pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_processed = preprocessor.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = tm.predict(X_valid_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def eval_metrics(self, dados_reais, dados_preditos):\n",
    "        roc_auc = roc_auc_score(dados_reais, dados_preditos)\n",
    "        return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = ModelEvaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.eval_metrics(y_train, y_train_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.eval_metrics(y_valid, y_valid_pred[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. etapa\n",
    "pipe = Pipeline([('imputer', MeanMedianImputer(variables=['RendaMensal',\n",
    "                                                          'NumeroDeDependentes'])),\n",
    "                 ('discretizer', EqualFrequencyDiscretiser(variables=['TaxaDeUtilizacaoDeLinhasNaoGarantidas',\n",
    "                                                                      'TaxaDeEndividamento',\n",
    "                                                                      'RendaMensal'])),\n",
    "                 ('scaler', SklearnTransformerWrapper(RobustScaler()))])\n",
    "dp = DataPreprocess(X_train, pipe)\n",
    "X_train_processed = dp.run()\n",
    "\n",
    "#---------------------#\n",
    "#2. etapa\n",
    "tm = TrainModels(dados_X=X_train_processed,\n",
    "                 dados_y = y_train)\n",
    "tm.train(model=LogisticRegression(penalty='l2', max_iter=1500, solver='newton-cholesky'))\n",
    "y_valid_pred = tm.predict(X_valid_processed)\n",
    "\n",
    "#---------------------#\n",
    "# 3.etapa\n",
    "me = ModelEvaluation()\n",
    "me.eval_metrics(y_valid, y_valid_pred[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_flow_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
